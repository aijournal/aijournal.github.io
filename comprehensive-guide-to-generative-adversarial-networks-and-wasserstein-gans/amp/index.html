<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">

    <title>Comprehensive Guide to Generative Adversarial Networks and Wasserstein GANs</title>

    <meta name="HandheldFriendly" content="True">
    <meta name="viewport" content="width=device-width,minimum-scale=1,initial-scale=1">

    <link rel="shortcut icon" href="../../favicon.png">

    <link rel="shortcut icon" href="../../favicon.png" type="image/png">
    <link rel="canonical" href="../index.html">
    <meta name="referrer" content="no-referrer-when-downgrade">
    
    <meta property="og:site_name" content="AI Journal">
    <meta property="og:type" content="article">
    <meta property="og:title" content="Comprehensive Guide to Generative Adversarial Networks and Wasserstein GANs">
    <meta property="og:description" content="Welcome to the world of Generative Models">
    <meta property="og:url" content="https://aijournal.github.io/comprehensive-guide-to-generative-adversarial-networks-and-wasserstein-gans/">
    <meta property="og:image" content="https://aijournal.github.io/content/images/2018/08/0-hLc7dg5PV6wsQR8S-1.jpg">
    <meta property="article:published_time" content="2018-08-28T16:46:22.000Z">
    <meta property="article:modified_time" content="2018-08-28T17:56:52.000Z">
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:title" content="Comprehensive Guide to Generative Adversarial Networks and Wasserstein GANs">
    <meta name="twitter:description" content="Welcome to the world of Generative Models">
    <meta name="twitter:url" content="https://aijournal.github.io/comprehensive-guide-to-generative-adversarial-networks-and-wasserstein-gans/">
    <meta name="twitter:image" content="https://aijournal.github.io/content/images/2018/08/0-hLc7dg5PV6wsQR8S-1.jpg">
    <meta name="twitter:label1" content="Written by">
    <meta name="twitter:data1" content="AI Journal">
    <meta name="twitter:site" content="@aijournalyt">
    <meta name="twitter:creator" content="@aijournalyt">
    <meta property="og:image:width" content="600">
    <meta property="og:image:height" content="315">
    
    <script type="application/ld+json">
{
    "@context": "https://schema.org",
    "@type": "Article",
    "publisher": {
        "@type": "Organization",
        "name": "AI Journal",
        "logo": {
            "@type": "ImageObject",
            "url": "https://aijournal.github.io/favicon.png",
            "width": 60,
            "height": 60
        }
    },
    "author": {
        "@type": "Person",
        "name": "AI Journal",
        "image": {
            "@type": "ImageObject",
            "url": "https://aijournal.github.io/content/images/2018/08/logo-1.png",
            "width": 500,
            "height": 500
        },
        "url": "https://aijournal.github.io/author/ai/",
        "sameAs": [
            "https://www.youtube.com/c/aijournal",
            "https://twitter.com/aijournalyt"
        ]
    },
    "headline": "Comprehensive Guide to Generative Adversarial Networks and Wasserstein GANs",
    "url": "https://aijournal.github.io/comprehensive-guide-to-generative-adversarial-networks-and-wasserstein-gans/",
    "datePublished": "2018-08-28T16:46:22.000Z",
    "dateModified": "2018-08-28T17:56:52.000Z",
    "image": {
        "@type": "ImageObject",
        "url": "https://aijournal.github.io/content/images/2018/08/0-hLc7dg5PV6wsQR8S-1.jpg",
        "width": 600,
        "height": 315
    },
    "description": "Welcome to the world of Generative Models",
    "mainEntityOfPage": {
        "@type": "WebPage",
        "@id": "https://aijournal.github.io/"
    }
}
    </script>

    <meta name="generator" content="Ghost 2.0">
    <link rel="alternate" type="application/rss+xml" title="AI Journal" href="../../rss/index.rss">

    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Merriweather:300,700,700italic,300italic%7COpen+Sans:700,600,400">
    <style amp-custom>html{font-family:sans-serif;-ms-text-size-adjust:100%;-webkit-text-size-adjust:100%}body{margin:0}article,aside,details,figcaption,figure,footer,header,main,menu,nav,section,summary{display:block}audio,canvas,progress,video{display:inline-block;vertical-align:baseline}audio:not([controls]){display:none;height:0}[hidden],template{display:none}a{background-color:transparent}a:active,a:hover{outline:0}abbr[title]{border-bottom:1px dotted}b,strong{font-weight:bold}dfn{font-style:italic}h1{margin:0.67em 0;font-size:2em}mark{background:#ff0;color:#000}small{font-size:80%}sub,sup{position:relative;vertical-align:baseline;font-size:75%;line-height:0}sup{top:-0.5em}sub{bottom:-0.25em}img{border:0}amp-img{border:0}svg:not(:root){overflow:hidden}figure{margin:1em 40px}hr{box-sizing:content-box;height:0}pre{overflow:auto}code,kbd,pre,samp{font-family:monospace, monospace;font-size:1em}button,input,optgroup,select,textarea{margin:0;color:inherit;font:inherit}button{overflow:visible}button,select{text-transform:none}button,html input[type="button"],input[type="reset"],input[type="submit"]{cursor:pointer;-webkit-appearance:button}button[disabled],html input[disabled]{cursor:default}button::-moz-focus-inner,input::-moz-focus-inner{padding:0;border:0}input{line-height:normal}input[type="checkbox"],input[type="radio"]{box-sizing:border-box;padding:0}input[type="number"]::-webkit-inner-spin-button,input[type="number"]::-webkit-outer-spin-button{height:auto}input[type="search"]{-webkit-appearance:textfield}input[type="search"]::-webkit-search-cancel-button,input[type="search"]::-webkit-search-decoration{-webkit-appearance:none}fieldset{margin:0 2px;padding:0.35em 0.625em 0.75em;border:1px solid #c0c0c0}legend{padding:0;border:0}textarea{overflow:auto}optgroup{font-weight:bold}table{border-spacing:0;border-collapse:collapse}td,th{padding:0}html{max-height:100%;height:100%;font-size:62.5%;-webkit-tap-highlight-color:rgba(0, 0, 0, 0)}body{max-height:100%;height:100%;color:#3a4145;background:#f4f8fb;letter-spacing:0.01rem;font-family:"Merriweather", serif;font-size:1.8rem;line-height:1.75em;text-rendering:geometricPrecision;-webkit-font-feature-settings:"kern" 1;-moz-font-feature-settings:"kern" 1;-o-font-feature-settings:"kern" 1}::-moz-selection{background:#d6edff}::selection{background:#d6edff}h1,h2,h3,h4,h5,h6{margin:0 0 0.3em 0;color:#2e2e2e;font-family:"Open Sans", sans-serif;line-height:1.15em;text-rendering:geometricPrecision;-webkit-font-feature-settings:"dlig" 1, "liga" 1, "lnum" 1, "kern" 1;-moz-font-feature-settings:"dlig" 1, "liga" 1, "lnum" 1, "kern" 1;-o-font-feature-settings:"dlig" 1, "liga" 1, "lnum" 1, "kern" 1}h1{text-indent:-2px;letter-spacing:-1px;font-size:2.6rem}h2{letter-spacing:0;font-size:2.4rem}h3{letter-spacing:-0.6px;font-size:2.1rem}h4{font-size:1.9rem}h5{font-size:1.8rem}h6{font-size:1.8rem}a{color:#4a4a4a}a:hover{color:#111}p,ul,ol,dl{margin:0 0 2.5rem 0;font-size:1.5rem;text-rendering:geometricPrecision;-webkit-font-feature-settings:"liga" 1, "onum" 1, "kern" 1;-moz-font-feature-settings:"liga" 1, "onum" 1, "kern" 1;-o-font-feature-settings:"liga" 1, "onum" 1, "kern" 1}ol,ul{padding-left:2em}ol ol,ul ul,ul ol,ol ul{margin:0 0 0.4em 0;padding-left:2em}dl dt{float:left;clear:left;overflow:hidden;margin-bottom:1em;width:180px;text-align:right;text-overflow:ellipsis;white-space:nowrap;font-weight:700}dl dd{margin-bottom:1em;margin-left:200px}li{margin:0.4em 0}li li{margin:0}hr{display:block;margin:1.75em 0;padding:0;height:1px;border:0;border-top:#efefef 1px solid}blockquote{box-sizing:border-box;margin:1.75em 0 1.75em 0;padding:0 0 0 1.75em;border-left:#4a4a4a 0.4em solid;-moz-box-sizing:border-box}blockquote p{margin:0.8em 0;font-style:italic}blockquote small{display:inline-block;margin:0.8em 0 0.8em 1.5em;color:#ccc;font-size:0.9em}blockquote small:before{content:"\2014 \00A0"}blockquote cite{font-weight:700}blockquote cite a{font-weight:normal}mark{background-color:#fdffb6}code,tt{padding:1px 3px;border:#e3edf3 1px solid;background:#f7fafb;border-radius:2px;white-space:pre-wrap;font-family:Inconsolata, monospace, sans-serif;font-size:0.85em;font-feature-settings:"liga" 0;-webkit-font-feature-settings:"liga" 0;-moz-font-feature-settings:"liga" 0}pre{overflow:auto;box-sizing:border-box;margin:0 0 1.75em 0;padding:10px;width:100%;border:#e3edf3 1px solid;background:#f7fafb;border-radius:3px;white-space:pre;font-family:Inconsolata, monospace, sans-serif;font-size:0.9em;-moz-box-sizing:border-box}pre code,pre tt{padding:0;border:none;background:transparent;white-space:pre-wrap;font-size:inherit}kbd{display:inline-block;margin-bottom:0.4em;padding:1px 8px;border:#ccc 1px solid;background:#f4f4f4;border-radius:4px;box-shadow:0 1px 0 rgba(0, 0, 0, 0.2), 0 1px 0 0 #fff inset;color:#666;text-shadow:#fff 0 1px 0;font-size:0.9em;font-weight:700}table{box-sizing:border-box;margin:1.75em 0;max-width:100%;width:100%;background-color:transparent;-moz-box-sizing:border-box}table th,table td{padding:8px;border-top:#efefef 1px solid;vertical-align:top;text-align:left;line-height:20px}table th{color:#000}table caption + thead tr:first-child th,table caption + thead tr:first-child td,table colgroup + thead tr:first-child th,table colgroup + thead tr:first-child td,table thead:first-child tr:first-child th,table thead:first-child tr:first-child td{border-top:0}table tbody + tbody{border-top:#efefef 2px solid}table table table{background-color:#fff}table tbody > tr:nth-child(odd) > td,table tbody > tr:nth-child(odd) > th{background-color:#f6f6f6}table.plain tbody > tr:nth-child(odd) > td,table.plain tbody > tr:nth-child(odd) > th{background:transparent}iframe,amp-iframe,.fluid-width-video-wrapper{display:block;margin:1.75em 0}.fluid-width-video-wrapper iframe,.fluid-width-video-wrapper amp-iframe{margin:0}textarea,select,input{margin:0 0 5px 0;padding:6px 9px;width:260px;outline:0;border:#e7eef2 1px solid;background:#fff;border-radius:4px;box-shadow:none;font-family:"Open Sans", sans-serif;font-size:1.6rem;line-height:1.4em;font-weight:100;-webkit-appearance:none}textarea{min-width:250px;min-height:80px;max-width:340px;width:100%;height:auto}input[type="text"]:focus,input[type="email"]:focus,input[type="search"]:focus,input[type="tel"]:focus,input[type="url"]:focus,input[type="password"]:focus,input[type="number"]:focus,input[type="date"]:focus,input[type="month"]:focus,input[type="week"]:focus,input[type="time"]:focus,input[type="datetime"]:focus,input[type="datetime-local"]:focus,textarea:focus{outline:none;outline-width:0;border:#bbc7cc 1px solid;background:#fff}select{width:270px;height:30px;line-height:30px}.clearfix:before,.clearfix:after{content:" ";display:table}.clearfix:after{clear:both}.clearfix{zoom:1}.main-header{position:relative;display:table;overflow:hidden;box-sizing:border-box;width:100%;height:50px;background:#5ba4e5 no-repeat center center;background-size:cover;text-align:left;-webkit-box-sizing:border-box;-moz-box-sizing:border-box}.content{background:#fff;padding-top:15px}.blog-title,.content{margin:auto;max-width:600px}.blog-title a{display:block;padding-right:16px;padding-left:16px;height:50px;color:#fff;text-decoration:none;font-family:"Open Sans", sans-serif;font-size:16px;line-height:50px;font-weight:600}.post{position:relative;margin-top:0;margin-right:16px;margin-left:16px;padding-bottom:0;max-width:100%;border-bottom:#ebf2f6 1px solid;word-wrap:break-word;font-size:0.95em;line-height:1.65em}.post-header{margin-bottom:1rem}.post-title{margin-bottom:0}.post-title a{text-decoration:none}.post-meta{display:block;margin:3px 0 0 0;color:#9eabb3;font-family:"Open Sans", sans-serif;font-size:1.3rem;line-height:2.2rem}.post-meta a{color:#9eabb3;text-decoration:none}.post-meta a:hover{text-decoration:underline}.post-meta .author{margin:0;font-size:1.3rem;line-height:1.3em}.post-date{display:inline-block;text-transform:uppercase;white-space:nowrap;font-size:1.2rem;line-height:1.2em}.post-image{margin:0;padding-top:3rem;padding-bottom:30px;border-top:1px #E8E8E8 solid}.post-content amp-img,.post-content amp-anim{position:relative;left:50%;display:block;padding:0;min-width:0;max-width:112%;width:calc(100% + 32px);height:auto;transform:translateX(-50%);-webkit-transform:translateX(-50%);-ms-transform:translateX(-50%)}.footnotes{font-size:1.3rem;line-height:1.6em;font-style:italic}.footnotes li{margin:0.6rem 0}.footnotes p{margin:0}.footnotes p a:last-child{text-decoration:none}.site-footer{position:relative;margin:0 auto 20px auto;padding:1rem 15px;max-width:600px;color:rgba(0,0,0,0.5);font-family:"Open Sans", sans-serif;font-size:1.1rem;line-height:1.75em}.site-footer a{color:rgba(0,0,0,0.5);text-decoration:none;font-weight:bold}.site-footer a:hover{border-bottom:#bbc7cc 1px solid}.poweredby{display:block;float:right;width:45%;text-align:right}.copyright{display:block;float:left;width:45%}</style>

    <style amp-boilerplate>body{-webkit-animation:-amp-start 8s steps(1,end) 0s 1 normal both;-moz-animation:-amp-start 8s steps(1,end) 0s 1 normal both;-ms-animation:-amp-start 8s steps(1,end) 0s 1 normal both;animation:-amp-start 8s steps(1,end) 0s 1 normal both}@-webkit-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@-moz-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@-ms-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@-o-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}</style><noscript><style amp-boilerplate>body{-webkit-animation:none;-moz-animation:none;-ms-animation:none;animation:none}</style></noscript>
    <script async src="https://cdn.ampproject.org/v0.js"></script>

    <script async custom-element="amp-iframe" src="https://cdn.ampproject.org/v0/amp-iframe-0.1.js"></script>

</head>

<body class="amp-template">
    <header class="main-header">
        <nav class="blog-title">
            <a href="../../index.html">AI Journal</a>
        </nav>
    </header>

    <main class="content" role="main">
        <article class="post">

            <header class="post-header">
                <h1 class="post-title">Comprehensive Guide to Generative Adversarial Networks and Wasserstein GANs</h1>
                <section class="post-meta">
                    <p class="author">by <a href="../../author/ai/index.html">AI Journal</a></p>
                    <time class="post-date" datetime="2018-08-28">2018-08-28</time>
                </section>
            </header>
            <figure class="post-image">
                <amp-img src="https://aijournal.github.io/content/images/2018/08/0-hLc7dg5PV6wsQR8S-1.jpg" width="600" height="400" layout="responsive"></amp-img>
            </figure>
            <section class="post-content">

                <figure class="kg-image-card"><figcaption>Progressive Growing of GANs</figcaption></figure><h3 id="overview">Overview</h3><p>The  year 2017 was a period of scientific breakthroughs in deep learning,  with the publication of numerous research papers. Every year seems like a  big leap toward artificial general intelligence, or AGI.</p><p>One exciting development involves generative modelling and the use of <a href="https://arxiv.org/abs/1701.07875" rel="nofollow noopener">Wasserstein GANs</a> (Generative Adversarial Networks). An influential paper on the topic  has completely changed the approach to generative modelling, moving  beyond the time when Ian Goodfellow published the original <a href="https://arxiv.org/pdf/1701.07875.pdf" rel="nofollow noopener">GAN paper</a>.</p><p>Why Wasserstein GANs are such a big deal:</p><ul><li>With  Wasserstein GAN, you can train the discriminator to convergence. If  true, it would totally remove the need to balance generator updates with  discriminator updates, as earlier the updates of generator and  discriminator were happening with no correlation to each other.</li><li>The initial paper (Soumith et al.) proposed a new GAN training algorithm that works well on the commonly used GAN datasets.</li><li>Usually  theory justified papers don’t provide good empirical results, but the  training algorithm mentioned in the paper is backed up by theory and it  explains why WGANs work so much better.</li></ul><h3 id="introduction">Introduction</h3><p>This  paper differs from earlier work: the training algorithm is backed up by  theory, and few examples exist where theory-justified papers gave good  empirical results. The big thing about WGANs is that developers can  train their discriminator to convergence, which was not possible  earlier. Doing this eliminates the need to balance generator updates  with discriminator updates.</p><figure class="kg-embed-card"><amp-iframe width="480" height="270" src="https://www.youtube.com/embed/M17D2j0QjoQ?feature=oembed" frameborder="0" allowfullscreen sandbox="allow-scripts allow-same-origin" layout="responsive"></amp-iframe></figure><h3 id="what-is-earth-mover-s-distance">What is Earth Mover’s Distance?</h3><p>When  dealing with discrete probability distributions, the Wasserstein  Distance is also known as Earth mover’s distance (EMD). Imagining  different heaps of earth in varying quantities, EMD would be the minimal  total amount of work it takes to transform one heap into another. Here,  work is defined as the product of the amount of earth being moved and  the distance it covers. Two discrete probability distributions are  usually defined as Pr and P(theta).</p><p>Pr comes from unknown distribution, and the goal is to learn P(theta) that approximates Pr.</p><p>Calculation of EMD is an optimization process with infinite solution approaches; the challenge is to find the optimal one.</p><figure class="kg-image-card"></figure><p>One  approach would be to directly learn probability density function  P(theta). This would mean that P(theta) is some differentiable function  that can be optimized by maximum likelihood estimation. To do that,  minimize the KL (Kullback–Leibler) divergence KL(Pr||(P(theta)) and add a  random noise to P(theta) when training the model for maximum likelihood  estimation. This ensures that distribution is defined elsewhere;  otherwise, if a single point lies outside P(theta), the KL divergence  can explode.</p><p>Adversarial  training makes it hard to see whether models are training. It has been  shown that GANs are related to actor-critic methods in reinforcement  learning. <a href="https://arxiv.org/abs/1610.01945" rel="nofollow noopener">Learn More</a>.</p><h3 id="kullback-leibler-and-jensen-shannon-divergence">Kullback–Leibler and Jensen–Shannon Divergence</h3><ol><li>KL  (Kullback–Leibler) divergence measures how one probability distribution  P diverges from a second expected probability distribution Q.</li></ol><figure class="kg-image-card"></figure><ul><li>We  drop −H(p) going from (18) − (19) because it is a constant. We can see  if we minimize the LHS (Left-hand side), we are maximizing the  expectation of log q(x) over the distribution <em>p</em>. Therefore, minimizing the LHS is maximizing the RHS, which is maximizing the log-likelihood of the data.</li></ul><p>DKL achieves the minimum zero when p(x) == q(x) everywhere.</p><p>It  is noticeable from the formula that KL divergence is asymmetric. In  cases where P(x) is close to zero, but Q(x) is significantly non-zero,  the q’s effect is disregarded. It could cause buggy results when the  intention was just to measure the similarity between two equally  important distributions.</p><ul><li>Jensen–Shannon  Divergence is another measure of similarity between two probability  distributions. JS (Jensen–Shannon) divergence is symmetric and  relatively smoother and is bounded by [0,1].</li></ul><p>Given  two Gaussian distributions, P with mean=0 and std=1 and Q with mean=1  and std=1. The average of two distributions is labelled as m=(p+q)/2. KL  divergence DKL is asymmetric but JS divergence DJS is symmetric.</p><figure class="kg-image-card"></figure><h3 id="generative-adversarial-network-gan-">Generative Adversarial Network (GAN)</h3><p>GAN consists of two models:</p><ul><li>A  discriminator D estimates the probability of a given sample coming from  the real dataset. It works as a critic and is optimized to tell the  fake samples from the real ones.</li><li>A  generator G outputs synthetic samples given a noise variable input z (z  brings in potential output diversity). It is trained to capture the  real data distribution so that its generative samples can be as real as  possible, or in other words, it can trick the discriminator to offer a  high probability.</li></ul><figure class="kg-embed-card"><amp-iframe width="480" height="270" src="https://www.youtube.com/embed/1gXs2S4GnqY?feature=oembed" frameborder="0" allowfullscreen sandbox="allow-scripts allow-same-origin" layout="responsive"></amp-iframe></figure><figure class="kg-image-card"></figure><h3 id="use-wasserstein-distance-as-gan-loss-function">Use Wasserstein Distance as GAN Loss Function</h3><p>It  is almost impossible to exhaust all the joint distributions in Π(pr,pg)  to compute infγ∼Π(pr,pg). Instead, the authors proposed a smart  transformation of the formula based on the Kantorovich-Rubinstein  duality:</p><figure class="kg-image-card"></figure><p>One big problem involves maintaining the K-Lipschitz continuity of fw  during the training to make everything work out. The paper presented a  simple but very practical noteworthy trick: after the gradient gets  updated, clamping the weights w to a small window is required, such as  [−0.01,0.01], resulting in a compact parameter space W; and thus, fw  obtains it’s lower and upper bounds in order to preserve the Lipschitz  continuity.</p><figure class="kg-image-card"></figure><p>Compared to the original GAN algorithm, the WGAN undertakes the following changes:</p><ul><li>After  every gradient update on the critic function, we are required to clamp  the weights to a small fixed range is required, usually [−c,c].</li><li>Use  a new loss function derived from the Wasserstein distance. The  discriminator model does not play as a direct critic but rather a helper  for estimating the Wasserstein metric between real and generated data  distributions.</li></ul><p>Empirically  the authors recommended usage of RMSProp optimizer on the critic,  rather than a momentum-based optimizer such as Adam which could cause  instability in the model training.</p><h3 id="improved-gan-training">Improved GAN Training</h3><p>The following suggestions are proposed to help stabilize and improve the training of GANs.</p><ul><li><strong>Adding noises — </strong>Based  on the discussion in the previous section, it is now known that Pr and  Pg are disjointed in a high dimensional space and they may become the  reason for the problem of vanishing gradient.To synthetically “spread  out” the distribution and to create higher chances for two probability  distributions to have overlaps, one solution is to add continuous noises  onto the inputs of the discriminator D.</li><li><strong>One-sided label smoothing — </strong>When  we are feeding the discriminator, instead of providing the labels as 1  and 0, this paper proposed using values such as 0.9 and 0.1. This will  help in reduce the vulnerabilities in Network.</li></ul><p>Wasserstein metric is proposed to replace JS divergence because it has a much smoother value space.</p><h3 id="overview-of-dcgan">Overview of DCGAN</h3><p>In  recent years, supervised learning with convolutional networks (CNNs)  has seen huge adoption in computer vision applications. As compared to  supervised learning, ConvNets have received little attention. Deep  convolutional generative adversarial networks (DCGANs) have certain  architectural constraints and demonstrate a strong potential for  unsupervised learning. Training on various image datasets show  convincing evidence that a deep convolutional adversarial pair learns a  hierarchy of representations from object parts to scenes in both the  generator and discriminator. Additionally, the learned features were  used for novel tasks — demonstrating their applicability as general  image representations.</p><figure class="kg-image-card"></figure><h3 id="problem-with-gans">Problem with GANs</h3><ol><li><strong>It’s harder to achieve Nash Equilibrium </strong>— Since  there are two neural networks (generator and discriminator), they are  being trained simultaneously to find a Nash Equilibrium. In the whole  process each player updates the cost function independently without  considering the updates of cost function by another network. This method  cannot assure a convergence, which is the stated objective.</li><li><strong>Vanishing gradient </strong>— When  the discriminator works as required, the distribution D(x) equals 1  when x belongs to Pr and vice versa. In this process, loss function L  fails to zero and results in no gradients to update the loss during the  training process. This figure shows that as the discriminator gets  increasingly better, the gradient vanishes fast, tending to 0.</li><li><strong>Use better metric of distribution similarity </strong>— The  loss function as proposed in the vanilla GAN (by Goodfellow et al.)  measures the JS divergence between the distributions of Pr and P(theta).  This metric fails to provide a meaningful value when two distributions  are disjointed.</li></ol><p>Replacing JS divergence with the Wasserstein metric gives a much smoother value space.</p><p>Training a Generative Adversarial Network faces a major problem:</p><ul><li>If  the discriminator works as required, the gradient of the loss function  starts tending to zero. As a process loss cannot be updated, training  becomes very slow or the model gets stuck.</li><li>If  the discriminator behaves badly, the generator does not have accurate  feedback and the loss function cannot represent the reality.</li></ul><h3 id="evaluation-metric">Evaluation Metric</h3><p>GANs  faced the problem of good objective function that can give better  insight of the whole training process. A good evaluation metric was  needed. Wasserstein Distance sought to address this problem.</p><h3 id="few-gans-applications">Few GANs Applications</h3><p>These  are some very few applications of GANs (just to provide some ideas) but  they can be extended to do so much than what we can possibly think of.  There are many papers which have made use of different architectures of  GANs, some are listed below:</p><ul><li>Font generation with conditional GANs</li><li>Interactive image generation</li><li>Image editing</li><li>Human pose estimation</li><li>Synthetic data generation</li><li>Visual saliency prediction</li><li>Adversarial examples (defense vs attack)</li><li>Image blending</li><li>Super resolution</li><li>Image inpainting</li><li>Face aging</li></ul><h3 id="code">Code</h3><p>The code can be found in this <a href="https://github.com/prajjwal1/gans" rel="nofollow noopener">Github* repository</a>.</p><h3 id="empirical-results">Empirical Results</h3><p>Initially  the paper (Soumith at al.) demonstrated the real difference between GAN  and WGAN. A GAN Discriminator and Wasserstein GAN critic are trained  optimality. In the following graph blue depicts real Gaussian  distribution and green depicts fake ones then the values are plotted.  The red curve depicts the GAN discriminator output.</p><figure class="kg-image-card"></figure><p>Both  GAN and WGAN will identify which distribution is fake and which ones are  real, but GAN Discriminator does this in such a way that gradients  vanish over this high dimensional space. WGANs make use of weight  clamping which gives them an edge and it which is able to give gradients  in almost every point in space. Wasserstein loss seems to correlate  well with image quality also.</p><p>This post was originally written for Intel AI Academy titled as <a href="https://software.intel.com/en-us/articles/better-generative-modelling-through-wasserstein-gans" rel="nofollow noopener">Better Generative modelling through Wasserstein GANs</a></p><blockquote><em>Visit </em><a href="https://www.youtube.com/c/aijournal" rel="noopener nofollow nofollow noopener"><em>AI Journal</em></a><em> for more videos. Don’t forget to</em><a href="https://www.youtube.com/c/aijournal?sub_confirmation=1" rel="noopener nofollow nofollow noopener"><em> subscribe</em></a><em> . Stay connected with us on </em><a href="https://twitter.com/aijournalyt" rel="noopener nofollow nofollow noopener"><em>Twitter</em></a><em> to stay updated in AI Research. Please support me on </em><a href="https://www.patreon.com/aijournal" rel="nofollow noopener nofollow noopener"><em>Patreon</em></a></blockquote>

            </section>

        </article>
    </main>
    <footer class="site-footer clearfix">
        <section class="copyright"><a href="../../index.html">AI Journal</a> © 2018</section>
        <section class="poweredby">Proudly published with <a href="https://ghost.org">Ghost</a></section>
    </footer>
</body>
</html>